{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://miro.medium.com/max/2200/1*XdCMCaHPt-pqtEibUfAnNw.png\" alt=\"\" height=\"20\" width=\"500\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras as kr\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten, BatchNormalization\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gzip\n",
    "import sklearn.preprocessing as pre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Train Images and Train Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('./train-images-idx3-ubyte.gz', 'rb') as f:\n",
    "    train_images = f.read()\n",
    "    \n",
    "with gzip.open('./train-labels-idx1-ubyte.gz', 'rb') as f:\n",
    "    train_labels = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Test Images and Test Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('./t10k-images-idx3-ubyte.gz', 'rb') as f:\n",
    "    test_images = f.read()\n",
    "    \n",
    "with gzip.open('./t10k-labels-idx1-ubyte.gz', 'rb') as f:\n",
    "    test_labels = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytes"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\x00\\x00\\x08\\x03'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Little and Big Endian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2051"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# little and big endian\n",
    "int.from_bytes(train_images[0:4], byteorder='big')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int.from_bytes(train_images[4:8], byteorder='big')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int.from_bytes(train_images[8:12], byteorder='big')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int.from_bytes(train_images[12:16], byteorder='big')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int.from_bytes(train_images[278:279], byteorder='big')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytes"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = train_images[16:800]\n",
    "\n",
    "type(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read image as byte vector size 784, convert to 28 x 28 numpy unint8 2D array\n",
    "image = ~np.array(list(train_images[16:800])).reshape(28,28).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x25d24a39ef0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Image labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int.from_bytes(train_labels[8:9], byteorder='big')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save images and labels as numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train images shape:  (60000, 28, 28)\n",
      "train labels shape:  (60000,)\n",
      "train inputs shape:  (60000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# read training images as bytes and convert to 2D matrix for CNN\n",
    "train_images = ~np.array(list(train_images[16:])).reshape(60000, 28, 28)\n",
    "\n",
    "# scale values between 0 and 1\n",
    "train_images / 255.0\n",
    "\n",
    "# read in training labels 0 - 9\n",
    "train_labels = np.array(list(train_labels[8:])).astype(np.uint8)\n",
    "\n",
    "# test images read as bytes and convert to 2D matrix for CNN\n",
    "test_images = ~np.array(list(test_images[16:])).reshape(10000, 28, 28)\n",
    "\n",
    "# scale values between 0 and 1\n",
    "test_images / 255.0\n",
    "\n",
    "# read in test labels 0 - 9\n",
    "test_labels = np.array(list(test_labels[8:])).astype(np.uint8)\n",
    "\n",
    "# inspect data shape\n",
    "print('train images shape: ', train_images.shape)\n",
    "print('train labels shape: ', train_labels.shape)\n",
    "\n",
    "# reshape numpy arrays for grayscale colour channel \n",
    "train_inputs = train_images.reshape(60000, 28, 28, 1)\n",
    "test_inputs = test_images.reshape(10000, 28, 28, 1)\n",
    "\n",
    "# check data after\n",
    "print('train inputs shape: ', train_inputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Hot Encode Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train label 0: 5, outputs 0: [0 0 0 0 0 1 0 0 0 0]\n",
      "\n",
      "At index 0, value is [[1 0 0 0 0 0 0 0 0 0]]\n",
      "At index 1, value is [[0 1 0 0 0 0 0 0 0 0]]\n",
      "At index 2, value is [[0 0 1 0 0 0 0 0 0 0]]\n",
      "At index 3, value is [[0 0 0 1 0 0 0 0 0 0]]\n",
      "At index 4, value is [[0 0 0 0 1 0 0 0 0 0]]\n",
      "At index 5, value is [[0 0 0 0 0 1 0 0 0 0]]\n",
      "At index 6, value is [[0 0 0 0 0 0 1 0 0 0]]\n",
      "At index 7, value is [[0 0 0 0 0 0 0 1 0 0]]\n",
      "At index 8, value is [[0 0 0 0 0 0 0 0 1 0]]\n",
      "At index 9, value is [[0 0 0 0 0 0 0 0 0 1]]\n",
      "\n",
      "test label 0: 7, outputs 0: [0 0 0 0 0 0 0 1 0 0]\n",
      "\n",
      "At index 0, value is [[1 0 0 0 0 0 0 0 0 0]]\n",
      "At index 1, value is [[0 1 0 0 0 0 0 0 0 0]]\n",
      "At index 2, value is [[0 0 1 0 0 0 0 0 0 0]]\n",
      "At index 3, value is [[0 0 0 1 0 0 0 0 0 0]]\n",
      "At index 4, value is [[0 0 0 0 1 0 0 0 0 0]]\n",
      "At index 5, value is [[0 0 0 0 0 1 0 0 0 0]]\n",
      "At index 6, value is [[0 0 0 0 0 0 1 0 0 0]]\n",
      "At index 7, value is [[0 0 0 0 0 0 0 1 0 0]]\n",
      "At index 8, value is [[0 0 0 0 0 0 0 0 1 0]]\n",
      "At index 9, value is [[0 0 0 0 0 0 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "# define label binarizer instance\n",
    "train_encoder = pre.LabelBinarizer()\n",
    "\n",
    "# fit the training labels\n",
    "train_encoder.fit(train_labels)\n",
    "\n",
    "# transform labels to categorical data\n",
    "train_outputs = train_encoder.transform(train_labels)\n",
    "\n",
    "print('train label 0: {}, outputs 0: {}\\n'.format(train_labels[0], train_outputs[0]))\n",
    "\n",
    "# loop and print encoder values\n",
    "for i in range(10):\n",
    "    print('At index {}, value is {}'.format(i, train_encoder.transform([i])))\n",
    "\n",
    "# test label binarizer\n",
    "test_encoder = pre.LabelBinarizer()\n",
    "\n",
    "# fit test labels\n",
    "test_encoder.fit(test_labels)\n",
    "\n",
    "# transform to categorical\n",
    "test_outputs = test_encoder.transform(test_labels)\n",
    "\n",
    "print('\\ntest label 0: {}, outputs 0: {}\\n'.format(test_labels[0], test_outputs[0]))\n",
    "\n",
    "# loop and print encoder values\n",
    "for i in range(10):\n",
    "    print('At index {}, value is {}'.format(i, test_encoder.transform([i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Aaron\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# add sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# add a 2D convolution layer, creates a convolution kernel which helps produce a tensor of outputs\n",
    "model.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(28, 28, 1)))\n",
    "\n",
    "# https://datascience.stackexchange.com/questions/53426/what-exactly-is-batchnormalization-in-keras\n",
    "# https://keras.io/layers/normalization/\n",
    "# normalizes input to the activation function\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# add another 2D layer\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "\n",
    "# normalize between layers\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# https://keras.io/layers/pooling/\n",
    "# Max pooling operation for spatial data\n",
    "# chooses the best features\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "# normalize between layers\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# 2D --> 1D\n",
    "model.add(Flatten())\n",
    "\n",
    "# add Dense layer to get all relevant data\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "# normalize between layers\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# add dense layer with softmax activation function for probability of 0-9 value\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 26, 26, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 24, 24, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 12, 12, 64)        256       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,201,034\n",
      "Trainable params: 1,200,458\n",
      "Non-trainable params: 576\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Aaron\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 632s 11ms/step - loss: 0.1004 - acc: 0.9698\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 628s 10ms/step - loss: 0.0291 - acc: 0.9916\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25d24a98d68>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_inputs, train_outputs, batch_size=128, epochs=2, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 53s 5ms/step\n",
      "0.038683432718506085 0.9861\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = model.evaluate(test_inputs, test_outputs)\n",
    "\n",
    "print(val_loss, val_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('mnist_conv2d.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = kr.models.load_model('mnist_conv2d.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At predictions index 50, number is a  6\n"
     ]
    }
   ],
   "source": [
    "predictions = new_model.predict([test_inputs])\n",
    "\n",
    "print('At predictions index 50, number is a ', np.argmax(predictions[50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x25d461f7cf8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(test_inputs[50].reshape(28, 28), cmap=plt.cm.binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://keras.io/examples/mnist_cnn/\n",
    "* https://github.com/ianmcloughlin/jupyter-teaching-notebooks/blob/master/mnist.ipynb\n",
    "* https://www.kaggle.com/kentaroyoshioka47/cnn-with-batchnormalization-in-keras-94\n",
    "* https://machinelearningmastery.com/how-to-develop-a-convolutional-neural-network-from-scratch-for-mnist-handwritten-digit-classification/\n",
    "* https://missinglink.ai/guides/keras/keras-conv2d-working-cnn-2d-convolutions-keras/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
